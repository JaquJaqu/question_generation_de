{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to \n",
    "# [Ramsri Goutham Golla](https://github.com/ramsrigouthamg) \n",
    "# [Suraj Patil](https://github.com/patil-suraj) \n",
    "# [renatoviolin](https://github.com/renatoviolin/Multiple-Choice-Question-Generation-T5-and-Text2Text)\n",
    "# for their T5 transformer, BERT and QG codes. Their notebooks were instrumental in crafting this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4Dk8IQXMAnym"
   },
   "outputs": [],
   "source": [
    "#!pip install torch torchvision\n",
    "#!pip install spacy==2.1.3 --upgrade --force-reinstall\n",
    "#!pip install -U nltk\n",
    "#!python -m spacy download en/de\n",
    "\n",
    "#!pip install gensim\n",
    "#!pip install git+https://github.com/boudinfl/pke.git !!!!!\n",
    "#!pip install bert-extractive-summarizer --upgrade --force-reinstall !!!\n",
    "#!pip install -U pywsd !!!\n",
    "#!pip install -U wn==0.0.23 !!!\n",
    "#!pip install flashtext!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AzsYNBGiAnyu",
    "outputId": "a62d23f0-0b60-43b8-d634-ac8ec70cc01b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warming up PyWSD (takes ~10 secs)... took 6.344625234603882 secs.\n",
      "[nltk_data] Downloading package stopwords to /home/jboeck/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/jboeck/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import nltk\n",
    "from summarizer import Summarizer\n",
    "from transformers import *\n",
    "import pprint\n",
    "import itertools\n",
    "import re\n",
    "import pke\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import requests\n",
    "import random\n",
    "from pywsd.similarity import max_similarity\n",
    "from pywsd.lesk import adapted_lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from flashtext import KeywordProcessor\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('popular')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Text and define Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bspText= \"Igel.txt\"\n",
    "#bspText= \"Waldtiere.txt\"\n",
    "#bspText= \"Recycling_Kap_3_2.txt\" \n",
    "#bspText= \"ORF_Elefant.txt\"\n",
    "#bspText= \"Krauter_2.txt\"\n",
    "#bspText= \"Krauter.txt\"\n",
    "#bspText= \"thermodynamik.txt\"\n",
    "#bspText= \"Pflanzen.txt\"\n",
    "\n",
    "f = open(bspText,\"r\")\n",
    "full_text = f.read()\n",
    "path = \"/home/workdrive/jboeck/Applications/QG/BAC/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NF7owGkeAnyw"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## BERT Extractive Summarizer\n",
    "Summarize the text using BERT Extractive Summarizer. This is used to extract the most relevant and useful sentences from the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "7iRmpxDwAnyw",
    "outputId": "3163b0d6-2a97-42de-e108-91d97dfceb81",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________summarized_text______________\n",
      "Wenn die Igel sich ein gutes\n",
      "Fettpolster angefressen haben,\n",
      "gehen sie schlafen. Zuerst ziehen\n",
      "sich die Igelmännchen zurück, je\n",
      "nach Witterung bereits Anfang Oktober. Zuletzt\n",
      "gehen die Jungigel in Winterschlaf, sie brauchen ihre Zeit, bis sie ein\n",
      "ausreichendes Winterschlafgewicht erreicht haben. Die durchschnittliche Dauer des Winterschlafs beträgt 5 bis 6\n",
      "Monate. Kurze Unterbrechungen sind normal, die Igel erwachen,\n",
      "bleiben im Nest und schlafen bald weiter. Manchmal sind Igel auch\n",
      "für wenige Tage aktiv und verlassen ihr Nest. Das Erwachen tritt meist bei länger anhaltenden Außentemperaturen\n",
      "um 10° C ein. Warum halten Igel eigentlich Winterschlaf? Sie bräuchten\n",
      "sehr viel Energie, um ihre Körpertemperatur auf 34°C zu halten. Diese Energie bekommen sie durch ihre Nahrung.\n",
      "______________________________________________________________________________________________\n",
      "_____________full_text___________________\n",
      "Wenn die Igel sich ein gutes\n",
      "Fettpolster angefressen haben,\n",
      "gehen sie schlafen. Zuerst ziehen\n",
      "sich die Igelmännchen zurück, je\n",
      "nach Witterung bereits Anfang Oktober. Es folgen die Igelweibchen,\n",
      "nachdem sie sich von der Jungenaufzucht erholt haben. Zuletzt\n",
      "gehen die Jungigel in Winterschlaf, sie brauchen ihre Zeit, bis sie ein\n",
      "ausreichendes Winterschlafgewicht erreicht haben. Wenigstens 500\n",
      "Gramm sollte ein junger Igel Anfang November wiegen, um den\n",
      "ersten Winterschlaf aus eigener Kraft zu überstehen.\n",
      "Im Winterschlaf sind alle Lebensfunktionen des Igels auf\n",
      "Sparflamme gesetzt.\n",
      "\n",
      "Die durchschnittliche Dauer des Winterschlafs beträgt 5 bis 6\n",
      "Monate. Kurze Unterbrechungen sind normal, die Igel erwachen,\n",
      "bleiben im Nest und schlafen bald weiter. Manchmal sind Igel auch\n",
      "für wenige Tage aktiv und verlassen ihr Nest.\n",
      "Das Einschlafen selbst dauert beim Igel rund 5-6 Stunden. Die Igel\n",
      "zehren danach in den nächsten Wochen und Monaten von ihrer\n",
      "Speckschicht, die sie sich im Sommer und Herbst angefressen haben.\n",
      "Das Erwachen tritt meist bei länger anhaltenden Außentemperaturen\n",
      "um 10° C ein.\n",
      "Warum halten Igel eigentlich Winterschlaf? Igel sind mit ihrem\n",
      "Stachelkleid ganz schlecht vor der Kälte geschützt. Sie bräuchten\n",
      "sehr viel Energie, um ihre Körpertemperatur auf 34°C zu halten.\n",
      "Diese Energie bekommen sie durch ihre Nahrung. Da es aber im\n",
      "Winter für den Igel kaum Futter gibt, würde er einfach verhungern\n",
      "und erfrieren.\n"
     ]
    }
   ],
   "source": [
    "#__BERT for text Summarization \n",
    "custom_config = AutoConfig.from_pretrained('distilbert-base-multilingual-cased') \n",
    "# may use other BERTs in future settings:\n",
    "    # bert-base-german-cased\n",
    "    # distilbert-base-german-cased\n",
    "\n",
    "custom_config.output_hidden_states=True # Whether or not the model should return all hidden-states.\n",
    "\n",
    "custom_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-multilingual-cased')\n",
    "custom_model = AutoModel.from_pretrained('distilbert-base-multilingual-cased', config=custom_config) #use autoconfig\n",
    "#print (\"device \",device)\n",
    "#model = model.to(device)\n",
    "\n",
    "model = Summarizer(custom_model=custom_model, custom_tokenizer=custom_tokenizer)\n",
    "model(full_text)\n",
    "result = model(full_text, min_length=10, ratio = 0.6) #Ratio of sentences to summarize to from the original body. (default to 0.2)\n",
    "\n",
    "summarized_text = ''.join(result)\n",
    "print (\"___________summarized_text______________\")\n",
    "print (summarized_text)\n",
    "print(\"______________________________________________________________________________________________\")\n",
    "print (\"_____________full_text___________________\")\n",
    "print (full_text)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#print(custom_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used for Thesis\n",
    "\n",
    "#### DistilBERT - multilingual\n",
    "___________summarized_text______________\n",
    "\n",
    "Wenn die Igel sich ein gutes\n",
    "Fettpolster angefressen haben,\n",
    "gehen sie schlafen. Zuerst ziehen\n",
    "sich die Igelmännchen zurück, je\n",
    "nach Witterung bereits Anfang Oktober. Zuletzt\n",
    "gehen die Jungigel in Winterschlaf, sie brauchen ihre Zeit, bis sie ein\n",
    "ausreichendes Winterschlafgewicht erreicht haben. Die durchschnittliche Dauer des Winterschlafs beträgt 5 bis 6\n",
    "Monate. Kurze Unterbrechungen sind normal, die Igel erwachen,\n",
    "bleiben im Nest und schlafen bald weiter. Manchmal sind Igel auch\n",
    "für wenige Tage aktiv und verlassen ihr Nest. Das Erwachen tritt meist bei länger anhaltenden Außentemperaturen\n",
    "um 10° C ein. Warum halten Igel eigentlich Winterschlaf? Sie bräuchten\n",
    "sehr viel Energie, um ihre Körpertemperatur auf 34°C zu halten. Diese Energie bekommen sie durch ihre Nahrung.\n",
    "\n",
    "_________________________________________________________________________________________________________________\n",
    "_________________________________________________________________________________________________________________\n",
    "\n",
    "### For future settings\n",
    "\n",
    "#### DistilBERT - german\n",
    "___________summarized_text______________\n",
    "\n",
    "Wenn die Igel sich ein gutes\n",
    "Fettpolster angefressen haben,\n",
    "gehen sie schlafen. Zuerst ziehen\n",
    "sich die Igelmännchen zurück, je\n",
    "nach Witterung bereits Anfang Oktober. Zuletzt\n",
    "gehen die Jungigel in Winterschlaf, sie brauchen ihre Zeit, bis sie ein\n",
    "ausreichendes Winterschlafgewicht erreicht haben. Im Winterschlaf sind alle Lebensfunktionen des Igels auf\n",
    "Sparflamme gesetzt. Die durchschnittliche Dauer des Winterschlafs beträgt 5 bis 6\n",
    "Monate. Manchmal sind Igel auch\n",
    "für wenige Tage aktiv und verlassen ihr Nest. Das Erwachen tritt meist bei länger anhaltenden Außentemperaturen\n",
    "um 10° C ein. Warum halten Igel eigentlich Winterschlaf? Igel sind mit ihrem\n",
    "Stachelkleid ganz schlecht vor der Kälte geschützt. Diese Energie bekommen sie durch ihre Nahrung. Da es aber im\n",
    "Winter für den Igel kaum Futter gibt, würde er einfach verhungern\n",
    "und erfrieren.\n",
    "\n",
    "#### German BERT\n",
    "___________summarized_text______________\n",
    "\n",
    "Wenn die Igel sich ein gutes\n",
    "Fettpolster angefressen haben,\n",
    "gehen sie schlafen. Zuletzt\n",
    "gehen die Jungigel in Winterschlaf, sie brauchen ihre Zeit, bis sie ein\n",
    "ausreichendes Winterschlafgewicht erreicht haben. Die durchschnittliche Dauer des Winterschlafs beträgt 5 bis 6\n",
    "Monate. Kurze Unterbrechungen sind normal, die Igel erwachen,\n",
    "bleiben im Nest und schlafen bald weiter. Manchmal sind Igel auch\n",
    "für wenige Tage aktiv und verlassen ihr Nest. Das Einschlafen selbst dauert beim Igel rund 5-6 Stunden. Warum halten Igel eigentlich Winterschlaf? Igel sind mit ihrem\n",
    "Stachelkleid ganz schlecht vor der Kälte geschützt. Sie bräuchten\n",
    "sehr viel Energie, um ihre Körpertemperatur auf 34°C zu halten. Diese Energie bekommen sie durch ihre Nahrung. Da es aber im\n",
    "Winter für den Igel kaum Futter gibt, würde er einfach verhungern\n",
    "und erfrieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLgXL1RcAnyx"
   },
   "source": [
    "## Keyword Extraction\n",
    "Get important keywords from the text and filter those keywords that are present in the summarized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Jg5gnoZXAnyx"
   },
   "outputs": [],
   "source": [
    "def get_nouns_multipartite(text):\n",
    "    out=[]\n",
    "    \n",
    "    nlp = spacy.load(\"de_core_news_sm\")\n",
    "    extractor = pke.unsupervised.MultipartiteRank()\n",
    "    extractor.load_document(input = bspText, language = 'de')\n",
    "    pos = {'NOUN'} # just use nouns as keywords\n",
    "    \n",
    "    stoplist = list(string.punctuation)\n",
    "    stoplist += stopwords.words('german') \n",
    "\n",
    "    \n",
    "    extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
    "    # 4. build the Multipartite graph and rank candidates using random walk,\n",
    "    #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
    "    #    threshold/method parameters.\n",
    "    extractor.candidate_weighting(alpha=1.1,\n",
    "                                  threshold=0.75,\n",
    "                                  method='average')\n",
    "    keyphrases = extractor.get_n_best(n=10)\n",
    "\n",
    "    for key in keyphrases:\n",
    "        out.append(key[0])\n",
    "    return out\n",
    "\n",
    "keywords = get_nouns_multipartite(full_text) \n",
    "filtered_keys=[] # just the keys in the summarized text\n",
    "\n",
    "for keyword in keywords:\n",
    "    keyword = keyword.capitalize()\n",
    "    if keyword in summarized_text: \n",
    "        filtered_keys.append(keyword)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAl-ief1Anyy"
   },
   "source": [
    "## Sentence Mapping\n",
    "For each keyword get the sentences from the summarized text containing that keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0Ytt673tAnyy",
    "outputId": "8022c77f-e16b-4097-c175-fbc9a80599c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___10 Best Sentences___\n",
      "\n",
      "\n",
      "Nr. 1 :\n",
      " Wenn die Igel sich ein gutes\n",
      "Fettpolster angefressen haben,\n",
      "gehen sie schlafen. \n",
      "\n",
      "Nr. 2 :\n",
      " Zuerst ziehen\n",
      "sich die Igelmännchen zurück, je\n",
      "nach Witterung bereits Anfang Oktober. \n",
      "\n",
      "Nr. 3 :\n",
      " Zuletzt\n",
      "gehen die Jungigel in Winterschlaf, sie brauchen ihre Zeit, bis sie ein\n",
      "ausreichendes Winterschlafgewicht erreicht haben. \n",
      "\n",
      "Nr. 4 :\n",
      " Die durchschnittliche Dauer des Winterschlafs beträgt 5 bis 6\n",
      "Monate. \n",
      "\n",
      "Nr. 5 :\n",
      " Kurze Unterbrechungen sind normal, die Igel erwachen,\n",
      "bleiben im Nest und schlafen bald weiter. \n",
      "\n",
      "Nr. 6 :\n",
      " Manchmal sind Igel auch\n",
      "für wenige Tage aktiv und verlassen ihr Nest. \n",
      "\n",
      "Nr. 7 :\n",
      " Das Erwachen tritt meist bei länger anhaltenden Außentemperaturen\n",
      "um 10° C ein. \n",
      "\n",
      "Nr. 8 :\n",
      " Warum halten Igel eigentlich Winterschlaf? \n",
      "\n",
      "Nr. 9 :\n",
      " Sie bräuchten\n",
      "sehr viel Energie, um ihre Körpertemperatur auf 34°C zu halten. \n",
      "\n",
      "Nr. 10 :\n",
      " Diese Energie bekommen sie durch ihre Nahrung. \n",
      "\n",
      "_______________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keywords = filtered_keys\n",
    "\n",
    "def tokenize_sentences(text):\n",
    "    sentences = [sent_tokenize(text)]\n",
    "    sentences = [y for x in sentences for y in x]\n",
    "    # Remove any short sentences less than 10 letters.\n",
    "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 10]\n",
    "    return sentences\n",
    "\n",
    "def get_sentences_for_keyword(keywords, sentences):\n",
    "    keyword_processor = KeywordProcessor()\n",
    "    keyword_sentences = {}\n",
    "    for word in keywords:\n",
    "        word = word.strip()\n",
    "        keyword_sentences[word] = []\n",
    "        keyword_processor.add_keyword(word)\n",
    "    for sentence in sentences:\n",
    "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
    "        for key in keywords_found:\n",
    "            keyword_sentences[key].append(sentence)\n",
    "\n",
    "    for key in keyword_sentences.keys():\n",
    "        values = keyword_sentences[key]\n",
    "        values = sorted(values, key=len, reverse=True)\n",
    "        keyword_sentences[key] = values\n",
    "\n",
    "    delete_keys = []\n",
    "    for k in keyword_sentences.keys():\n",
    "        if len(keyword_sentences[k]) == 0:\n",
    "            delete_keys.append(k)\n",
    "    for del_key in delete_keys:\n",
    "        del keyword_sentences[del_key]\n",
    "    return keyword_sentences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sentences = tokenize_sentences(summarized_text) #!!!\n",
    "keyword_sentence_mapping = get_sentences_for_keyword(filtered_keys, sentences)\n",
    "\n",
    "print(\"___10 Best Sentences___\")\n",
    "print(\"\\n\")\n",
    "index_number = 1\n",
    "for sentence in sentences:\n",
    "    \n",
    "    print(\"Nr.\",index_number,':\\n',sentence,'\\n')\n",
    "    index_number= index_number + 1 \n",
    "print('_______________________________________________________')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2IwHlwhAnyz"
   },
   "source": [
    "## Additional Distractor generation \n",
    "####  For MCQ Questions, not used in this thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DG_Ygdz9Anyz",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Possible Distractors not used within the thesis\n",
    "\n",
    "# def get_wordsense(sent,word):\n",
    "#     word= word.lower()\n",
    "#     if len(word.split())>0:\n",
    "#         word = word.replace(\" \",\"_\")   \n",
    "#     synsets = wn.synsets(word,'n')\n",
    "#     if synsets:\n",
    "#         wup = max_similarity(sent, word, 'wup', pos='n')\n",
    "#         adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n",
    "#         lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n",
    "#         return synsets[lowest_index]\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "    \n",
    "# #German Distractors using Conceptnet   \n",
    "# def get_distractors_conceptnet(word):\n",
    "#     word = word.lower()\n",
    "#     original_word= word\n",
    "#     if (len(word.split())>0):\n",
    "#         word = word.replace(\" \",\"_\")\n",
    "#     distractor_list = [] \n",
    "#     #url = \"http://api.conceptnet.io/query?filter=/c/de/node=/c/de/%s/n&rel=/r/PartOf&start=/c/de/%s&limit=5\"%(word,word)\n",
    "#     url = \"http://api.conceptnet.io/query?node=/c/de/%s/n&rel=/r/IsA&start=/c/de/%s&limit=5\"%(word,word)\n",
    "#     #url = \"http://api.conceptnet.io/query?node=/c/de/%s/n&rel=/r/TypeOf&start=/c/de/%s&limit=5\"%(word,word)\n",
    "#     #url = \"http://api.conceptnet.io/query?node=/c/de/%s/n&rel=/r/RelatedTo&start=/c/de/%s&limit=5\"%(word,word)\n",
    "#     obj = requests.get(url).json()\n",
    "   \n",
    "#     for edge in obj['edges']:\n",
    "#         link = edge['end']['term'] \n",
    "#         #url2 = \"http://api.conceptnet.io/query?filter=/c/de/node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
    "#         url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/IsA&end=%s&limit=10\"%(link,link)\n",
    "#         #url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/TypeOf&end=%s&limit=10\"%(link,link)\n",
    "#         #url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/RelatedTo&end=%s&limit=10\"%(link,link)\n",
    "#         obj2 = requests.get(url2).json()\n",
    "#         for edge in obj2['edges']:\n",
    "#             word2 = edge['start']['label']\n",
    "           \n",
    "#             if word2 not in distractor_list and original_word.lower() not in word2.lower():\n",
    "#                 distractor_list.append(word2)\n",
    "#     return distractor_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# key_distractor_list = {}\n",
    "# # print(keyword_sentence_mapping)\n",
    "\n",
    "# for keyword in keyword_sentence_mapping: \n",
    "#     wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword) \n",
    "#     if wordsense:\n",
    "#         if len(distractors) ==0:\n",
    "#             distractors = get_distractors_conceptnet(keyword)\n",
    "#         if len(distractors) != 0:\n",
    "#             key_distractor_list[keyword] = distractors\n",
    "#     else:\n",
    "#         distractors = get_distractors_conceptnet(keyword)\n",
    "#         if len(distractors) != 0:\n",
    "#             key_distractor_list[keyword] = distractors   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEYWORDS:  ['Igel', 'Winterschlaf', 'Monate', 'Nest', 'Energie', 'Dauer']\n",
      "_________________\n",
      "\n",
      "\n",
      "Kurze Unterbrechungen sind normal, die Igel erwachen,\n",
      "bleiben im Nest und schlafen bald weiter.\n",
      "\n",
      "\n",
      "Zuletzt\n",
      "gehen die Jungigel in Winterschlaf, sie brauchen ihre Zeit, bis sie ein\n",
      "ausreichendes Winterschlafgewicht erreicht haben.\n",
      "\n",
      "\n",
      "Die durchschnittliche Dauer des Winterschlafs beträgt 5 bis 6\n",
      "Monate.\n",
      "\n",
      "\n",
      "Kurze Unterbrechungen sind normal, die Igel erwachen,\n",
      "bleiben im Nest und schlafen bald weiter.\n",
      "\n",
      "\n",
      "Sie bräuchten\n",
      "sehr viel Energie, um ihre Körpertemperatur auf 34°C zu halten.\n",
      "\n",
      "\n",
      "Die durchschnittliche Dauer des Winterschlafs beträgt 5 bis 6\n",
      "Monate.\n"
     ]
    }
   ],
   "source": [
    "print(\"KEYWORDS: \", keywords)\n",
    "print('_________________')\n",
    "\n",
    "for keyword in keywords:\n",
    "    print('\\n')\n",
    "    print(keyword_sentence_mapping[keyword][0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4DJbjVcAny0"
   },
   "source": [
    "# Input Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OFtDt_YOAny1",
    "outputId": "3676a7b7-0445-4088-8142-8ef27a6394a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device  cuda\n"
     ]
    }
   ],
   "source": [
    "trained_model_path = path + 't5/model/'\n",
    "trained_tokenizer =  path + 't5/tokenizer/'\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(trained_model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(trained_tokenizer)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"device \",device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0S1MwomRAny1"
   },
   "source": [
    "## load finetuned T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs_for_qg_from_answers_hl(sents, answer):\n",
    "        inputs = []\n",
    "        sents = sents\n",
    "        #print(sents)\n",
    "        sents_copy = sents[:]\n",
    "        answer_copy = answer[:]\n",
    "        answer_text = answer_copy.strip()\n",
    "        answer_text = \"\".join(answer_text)\n",
    "        answer_text = answer_text.capitalize()\n",
    "        #print(\"ANSWER TEXT:\", answer_text)\n",
    "        ans_start_idx = sents.index(answer_text)\n",
    "#         print(ans_start_idx)      \n",
    "#         print(type(sents))\n",
    "#         print(len(answer_text))\n",
    "        generate=\"generate question: \"\n",
    "        contextstr=\"context: \"\n",
    "        answerstr=\"answer: \"\n",
    "        \n",
    "        #Experiments\n",
    "        #sent = f\"{generate}{sents[:ans_start_idx]} <hl> {answer_text} <hl> {sents[ans_start_idx + len(answer_text): ]}</s>\"\n",
    "        #sent = f\"{generate}{sents[:ans_start_idx]} <hl> {answer_text} <hl> {sents[ans_start_idx + len(answer_text): ]}\"\n",
    "        #sent = f\"{sents[:ans_start_idx]} <hl>{answer_text}<hl> {sents[ans_start_idx + len(answer_text): ]}\"\n",
    "        #sent = f\"{contextstr}{sents[:ans_start_idx]}<hl>{answer_text}<hl>{sents[ans_start_idx + len(answer_text): ]}</s><hl>{answerstr}{answer_text}<hl>\" #USED FOR BAC\n",
    "        sent = f\"{contextstr}{sents[:ans_start_idx]}{answer_text}{sents[ans_start_idx + len(answer_text): ]}<hl>{answerstr}{answer_text}<hl></s>\"\n",
    "        #sent = f\"{contextstr}{sents[:ans_start_idx]}<hl>{answer_text}<hl>{sents[ans_start_idx + len(answer_text): ]}{answerstr}<hl>{answer_text}<hl>\"\n",
    "        #sent = f\"{generate}{sents[:ans_start_idx]} <hl> {answer_text} <hl> {sents[ans_start_idx + len(answer_text): ]}</s><hl>{answerstr}{answer_text}<hl>\"\n",
    "        #sent = f\"{answerstr}<hl>{answer_text}<hl> {contextstr}{sents[:ans_start_idx]}<hl>{answer_text}<hl>{sents[ans_start_idx + len(answer_text): ]}\"\n",
    "        \n",
    "        #sents_copy = sents\n",
    "        #print(\"sent\", sent) \n",
    "        #print(\"sents_copy\", sents_copy)\n",
    "        #print(\"SENT\", sent)\n",
    "        #print(\"SENTS_COPY\", sents_copy)\n",
    "            \n",
    "#         source_text = \"\".join(sents_copy)\n",
    "#         source_text = f\"generate question: {source_text}\" \n",
    "#         print(type(source_text))\n",
    "#         source_text = source_text + \" </s>\"\n",
    "               \n",
    "        #inputs.append({\"answer\": answer_text, \"source_text\": sent})\n",
    "#                 #print(inputs)\n",
    "        #inputs.append({ \"generate questions\": sent})\n",
    "        #return sents_copy\n",
    "        return sent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxBrzJ_CAny2"
   },
   "source": [
    "# Question Generation with T5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qX167F3PAny2"
   },
   "outputs": [],
   "source": [
    "def t2t_qg_with_t5(Q_numb,context,answer):\n",
    "    print(\"\\n\")\n",
    "    #Q_numb; \n",
    "    text = context\n",
    "    answer = answer.capitalize()\n",
    "    print(\"INPUT:\", text)\n",
    "    print(\"\\n\")\n",
    "    encoding = tokenizer.encode_plus(text,max_length =512, padding=True, return_tensors=\"pt\")\n",
    "    input_ids,attention_mask  = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    beam_outputs = model.generate(\n",
    "    input_ids=input_ids,attention_mask=attention_mask,\n",
    "    max_length=72,\n",
    "    temperature = 0.05, #amount of randomness #\n",
    "    early_stopping=True,\n",
    "    num_beams=30, #beam: number of pads that we consider \n",
    "    num_return_sequences=10 \n",
    ")   \n",
    "    print(\"All_Question_Choices\")\n",
    "    for beam_output in beam_outputs:\n",
    "        Q_numb= Q_numb + 1\n",
    "        question = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "        #print(type(question))\n",
    "        question = \" \".join(question.split()[1:]) #remove first \"question:\" -string\n",
    "        print (str(Q_numb) +\":\",question)\n",
    "    return question\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "nGjjioMpAny3",
    "outputId": "5e3b06ac-1acb-496f-ddfa-c2129c975097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______Questionaire______________________________\n",
      "_____________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "INPUT: context: Kurze Unterbrechungen sind normal, die Igel erwachen,\n",
      "bleiben im Nest und schlafen bald weiter.<hl>answer: Igel<hl></s>\n",
      "\n",
      "\n",
      "All_Question_Choices\n",
      "1: Was bleibt im Nest und schlafen bald?\n",
      "2: Was bleiben im Nest und schlafen bald?\n",
      "3: Wer bleibt im Nest und schlaft bald?\n",
      "4: Wie erwachen Kurze Unterbrechungen?\n",
      "5: Wer bleibt im Nest und schlafen bald?\n",
      "6: Was bleibt im Nest und schlaft bald?\n",
      "7: Wer bleibt im Nest und schlaft bald?\n",
      "8: Was bleibt normal im Nest und schlafen bald?\n",
      "9: Wer bleibt normal im Nest und schlaft bald?\n",
      "10: Was bleibt im Nest und schlafen bald?\n",
      "11: Was bleibt im Nest und schlafen bald weiter?\n",
      "12: Wer bleiben im Nest und schlafen bald?\n",
      "13: Was bleibt im Nest?\n",
      "14: Wer bleibt im Nest und schlaft bald weiter?\n",
      "15: Wer bleibt im Nest und schlafen bald?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INPUT: context: Zuletzt\n",
      "gehen die Jungigel in Winterschlaf, sie brauchen ihre Zeit, bis sie ein\n",
      "ausreichendes Winterschlafgewicht erreicht haben.<hl>answer: Winterschlaf<hl></s>\n",
      "\n",
      "\n",
      "All_Question_Choices\n",
      "1: Wann brauchen sie ein ausreichendes Winterschlafgewicht?\n",
      "2: Wann braucht sie ein ausreichendes Winterschlafgewicht?\n",
      "3: In welchem Winterschlaf braucht Jungigel Zeit?\n",
      "4: In welchem Winterschlaf braucht die Jungigel Zeit?\n",
      "5: In welchem Winterschlaf brauchen Jungigel Zeit?\n",
      "6: In welchem Winterschlaf benötigen Jungigel Zeit?\n",
      "7: In welchem Winterschlaf benötigen Jungigel seine Zeit?\n",
      "8: In welchem Winterschlaf braucht Jungigel ihre Zeit?\n",
      "9: In welchem Winterschlaf haben Jungigel genug Zeit?\n",
      "10: In welchem Winterschlaf benötigen Jungigel ihre Zeit?\n",
      "11: In welchem Winterschlaf braucht der Jungigel seine Zeit?\n",
      "12: In welchem Winterschlaf brauchen Jungigel ihre Zeit?\n",
      "13: In welchem Winterschlaf müssen Jungigel ihre Zeit verbringen?\n",
      "14: In welchem Winterschlaf müssen Jungigel ihre Zeit haben?\n",
      "15: In welchem Winterschlaf müssen Jungigel ihre Zeit brauchen?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INPUT: context: Die durchschnittliche Dauer des Winterschlafs beträgt 5 bis 6\n",
      "Monate.<hl>answer: Monate<hl></s>\n",
      "\n",
      "\n",
      "All_Question_Choices\n",
      "1: Wie lange beträgt die durchschnittliche Dauer des Winterschlafs?\n",
      "2: Wie lange betragen die durchschnittliche Dauer des Winterschlafs?\n",
      "3: Wann beträgt die durchschnittliche Dauer des Winterschlafs?\n",
      "4: Welche Monate betragen die durchschnittliche Dauer des Winterschlafs?\n",
      "5: Welche Monate sind die durchschnittliche Dauer des Winterschlafs?\n",
      "6: Wann wird die durchschnittliche Dauer des Winterschlafs betragen?\n",
      "7: Wie lange beträgt der durchschnittliche Dauer des Winterschlafs?\n",
      "8: Wie lange ist die durchschnittliche Dauer des Winterschlafs?\n",
      "9: Wie lange beträgt die Dauer des Winterschlafs?\n",
      "10: Wie lange beträgt die Durchschnittsdauer des Winterschlafs?\n",
      "11: Wer beträgt die durchschnittliche Dauer des Winterschlafs?\n",
      "12: Wie lange beträgt der Durchschnitt des Winterschlafs?\n",
      "13: Wie lange beträgt der durchschnittliche Zeitraum des Winterschlafs?\n",
      "14: Wann beträgt die durchschnittliche Dauer des Winterschlafs?\n",
      "15: Wie lange beträgt die durchschnittliche Dauer der Winterschlafs?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INPUT: context: Kurze Unterbrechungen sind normal, die Igel erwachen,\n",
      "bleiben im Nest und schlafen bald weiter.<hl>answer: Nest<hl></s>\n",
      "\n",
      "\n",
      "All_Question_Choices\n",
      "1: Was bleibt im Nest und schlafen bald?\n",
      "2: Was bleiben im Nest und schlafen bald?\n",
      "3: Wo bleiben Kurze Unterbrechungen normal?\n",
      "4: Was bleibt im Nest schlafen bald?\n",
      "5: Wie bleiben Kurze Unterbrechungen normal?\n",
      "6: Wer bleibt im Nest und schlafen bald?\n",
      "7: Was bleibt bei kurzen Unterbrechungen normal?\n",
      "8: Wo bleiben Kurze Unterbrechungen bald?\n",
      "9: Was bleibt bei Kurze Unterbrechungen normal?\n",
      "10: Was bleibt im Nest und schlafen bald?\n",
      "11: Wer bleibt im Nest und schlaft bald?\n",
      "12: Wie bleiben Kurze Unterbrechungen im Nest?\n",
      "13: Was bleibt im Kurzen Unterbrechungen normal?\n",
      "14: Was bleibt im Nest?\n",
      "15: Wo bleiben kurze Unterbrechungen normal?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INPUT: context: Sie bräuchten\n",
      "sehr viel Energie, um ihre Körpertemperatur auf 34°C zu halten.<hl>answer: Energie<hl></s>\n",
      "\n",
      "\n",
      "All_Question_Choices\n",
      "1: Wie viel Energie bräuchten Sie?\n",
      "2: Wie bräuchten Sie viel Energie?\n",
      "3: Welche Art von Energie bräuchten Sie?\n",
      "4: Wozu bräuchten Sie viel Energie?\n",
      "5: Was bräuchten Sie?\n",
      "6: Was bräuchten Sie sehr viel?\n",
      "7: Wie viel Energie haben Sie bräuchten?\n",
      "8: Wie viel Energie bräuchten Sie? question\n",
      "9: Wie bräuchten Sie sehr viel Energie?\n",
      "10: Welche Art von Energie bräuchten Sie? question\n",
      "11: Wodurch bräuchten Sie viel Energie?\n",
      "12: Was bräuchten Sie für Ihre Körpertemperatur?\n",
      "13: Wovon bräuchten Sie viel?\n",
      "14: Wer bräuchte viel Energie?\n",
      "15: Welche Art von Energie bräuchten Sie sehr viel?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "INPUT: context: Die durchschnittliche Dauer des Winterschlafs beträgt 5 bis 6\n",
      "Monate.<hl>answer: Dauer<hl></s>\n",
      "\n",
      "\n",
      "All_Question_Choices\n",
      "1: Wie lange beträgt der Durchschnitt des Winterschlafs?\n",
      "2: Wie lange beträgt die Durchschnittsdauer des Winterschlafs?\n",
      "3: Was beträgt die durchschnittliche Dauer des Winterschlafs?\n",
      "4: Wie lange ist die durchschnittliche Dauer des Winterschlafs?\n",
      "5: Was ist die durchschnittliche Dauer des Winterschlafs?\n",
      "6: Wie lange beträgt die Dauer des Winterschlafs?\n",
      "7: Welche Dauer des Winterschlafs beträgt 5 bis 6 Monate?\n",
      "8: Wie lange wird der Durchschnitt des Winterschlafs betragen?\n",
      "9: Wie lange beträgt der Durchschnitt der Winterschlafzeiten?\n",
      "10: Wie lange beträgt der Durchschnitt des Winterschlafs?\n",
      "11: Wie lange ist der Durchschnitt des Winterschlafs?\n",
      "12: Wie lange beträgt der Durchschnitt der Winterschlafsdauer?\n",
      "13: Wie lange betragen die durchschnittlichen Winterschlafzeiten?\n",
      "14: Wie lange wird die Dauer des Winterschlafs betragen?\n",
      "15: Was ist die durchschnittliche Dauer des Winterschlafs?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('______Questionaire______________________________')\n",
    "print('_____________________________________________________________'+ \"\\n\")\n",
    "\n",
    "#print(key_distractor_list)\n",
    "index = 1\n",
    "Q_numb = 0\n",
    "for keyword in keywords:   \n",
    "    sentence = keyword_sentence_mapping[keyword][0] # get sentence for keyword\n",
    "        \n",
    "    #keyword =keyword.capitalize()\n",
    "    #print(keyword)\n",
    "    #__Question Generaion___\n",
    "    qg_examples = prepare_inputs_for_qg_from_answers_hl(sentence, keyword)   \n",
    "    question_t5= t2t_qg_with_t5(Q_numb, qg_examples,keyword)\n",
    "    #_numb = Q_numb+1\n",
    "    \n",
    "#____for Multiple Choice_______________ \n",
    "    #choices = [keyword.capitalize()] + key_distractor_list[keyword]\n",
    "    #top4choices = choices[:4]\n",
    "    #random.shuffle(top4choices)\n",
    "#     optionchoices = ['a','b','c','d']\n",
    "#     for idx,choice in enumerate(top4choices):\n",
    "#         print (\"\\t\",optionchoices[idx],\")\",\" \",choice.capitalize())\n",
    "#         #print (\"\\t\",optionchoices[idx],\")\",\" \",choice)\n",
    "#     print (\"\\nMore options: \", choices[4:20],\"\\n\\n\")\n",
    "#________________________________________________________________________\n",
    "    index = index + 1 \n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UnCqjVEOAny3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OdOhjIoZAny3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zMUWCOuAAny3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<hl>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([32101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sep>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([32100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "BAC_Question Generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
